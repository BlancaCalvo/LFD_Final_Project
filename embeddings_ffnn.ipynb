{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13ymSU11WvDa"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2fl8SDXXT00"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHmHJKwSk2bY"
   },
   "outputs": [],
   "source": [
    "!pip3 install importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9hG3y--mRX5"
   },
   "outputs": [],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "\n",
    "bt = SourceFileLoader('baseline', \"/content/drive/Shared drives/Shared Task SentiMix/tools/baseline.py\").load_module()\n",
    "data_tools = SourceFileLoader('data_tools', \"/content/drive/Shared drives/Shared Task SentiMix/tools/data.py\").load_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqaHYo_UWvDc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# tool_path = \"/content/drive/Shared drives/Shared Task SentiMix/tools\"\n",
    "\n",
    "# import tools\n",
    "\n",
    "# import tools.baseline as bt\n",
    "# import tools.data as data_tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding, Bidirectional, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from keras.optimizers import Adam\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from keras.layers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(corpus_file, use_binary):\n",
    "    \"\"\"read input document and return the textual articles\n",
    "    and either the bias or hyperpartisan label\"\"\"\n",
    "\n",
    "    with open(corpus_file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    documents = data.sentences\n",
    "\n",
    "    if use_binary == 0:\n",
    "        labels = data.hyperp\n",
    "    else:\n",
    "        labels = data.bias\n",
    "\n",
    "    return documents, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = read_corpus('tokenised_full.json', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27990                                                    []\n",
      "80593     [the, las, cruces, sun-news, reported, that, t...\n",
      "93952     [this, post, first, appeared, at, the, america...\n",
      "88847     [pasquale, ?, pat, ?, d, ?, arco, passed, away...\n",
      "91146     [jan, 25, (, ), -, wolong, real, estate, group...\n",
      "                                ...                        \n",
      "210143    [june, 6, is, a, very, special, day, in, ameri...\n",
      "206861    [british, police, say, their, investigation, i...\n",
      "184344    [msnbc, ?, s, joe, scarborough, told, his, aud...\n",
      "187353    [a, north, carolina, man, is, suing, philadelp...\n",
      "125208    [states, remained, stingy, in, funding, public...\n",
      "Name: sentences, Length: 48467, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size = 0.2, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuAJJFJmWvDm"
   },
   "outputs": [],
   "source": [
    "toki = Tokenizer()\n",
    "toki.fit_on_texts(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4mEdrNxWvDq"
   },
   "outputs": [],
   "source": [
    "Xtrain_seq = toki.texts_to_sequences(Xtrain)\n",
    "Xtest_seq = toki.texts_to_sequences(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fLPNbFAWvDt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1847, 1069, 39, 38, 209, 30780, 40650, 34, 583, 58366, 1363, 127255, 1332, 698, 533, 1158, 90, 6, 321, 632, 583, 19817, 127256, 2899, 533, 1158, 90, 2, 383, 268, 603, 21, 193, 17, 703, 1014, 603, 583, 14618, 127257, 7684, 30780, 127258, 3, 44782, 15, 533, 1158, 90, 2, 372, 2157, 2, 2003, 2, 350, 1954, 6, 1673, 81, 487, 34, 1, 626, 478, 616, 39, 38, 209, 71, 1610, 634, 321, 7705, 9217, 143, 90, 386, 86, 94, 161, 9, 25, 11, 32, 7, 988, 5, 686, 2759, 1213, 3626, 3, 12, 353, 628, 2, 117, 4, 7, 429, 1759, 16, 1, 3323, 71, 1610, 634, 321, 7705, 9217, 2693, 20, 7, 136, 661, 16, 79, 179, 1092, 225, 20, 1, 514, 222, 4, 3753, 1478, 7706, 1189, 16, 4634, 1113, 3216, 3862, 204, 2, 8, 214, 2, 71, 2, 333, 1287, 2, 532, 13221, 13633, 70, 1, 473, 663, 2307, 16, 9217, 2, 86, 143, 3901, 9, 25, 18, 32, 8259, 4, 1647, 1, 11966, 5, 736, 324, 121, 25, 11, 32, 1, 988, 5, 3626, 3, 12, 3323, 1, 2307, 18, 100, 241, 19, 3475, 1, 514, 222, 143, 14, 215, 32, 754, 13, 3644, 16, 1, 90, 1, 221, 158, 127, 32, 1513, 4, 7, 1325, 10, 754, 3626, 11, 2816, 1600, 5, 530, 5525, 8, 1, 307, 71, 269, 6, 559, 6605, 16, 1, 86, 204, 353, 30, 1473, 6217, 8, 1, 269, 86, 30, 22, 64, 18, 78, 6605, 6, 30, 1947, 239, 1, 3626, 3323, 7, 3, 10117, 4100, 2, 3, 1565, 934, 25, 259, 706, 4, 636, 1, 686, 2759, 43, 9217, 2, 50, 6904, 1, 628, 168, 514, 222, 212, 2, 7, 988, 11, 755, 50, 11, 1604, 4, 26, 1620, 7, 1044, 6, 11, 300, 4, 615, 871, 2, 109, 7, 1368, 11, 755, 653, 2029, 11, 507, 1, 4835, 5, 35, 628, 2, 22, 4836, 13937, 12506, 2, 7, 216, 180, 3262, 6, 7, 1244, 20, 4595, 363, 234, 5, 179, 1, 214, 549, 241, 395, 31, 265, 9, 86, 11, 7, 1368, 5, 1, 3323, 12506, 22, 1, 12341, 24, 9217, 11, 32, 855, 105, 1, 90, 87, 317, 408, 7, 988, 5, 1, 628, 3, 14, 11, 559, 4, 1488, 24, 129, 7, 1368, 4, 129, 7, 988, 66, 1, 1373, 8762, 6, 5804, 231, 10591, 346, 2, 3, 82, 22, 12506, 22, 56, 658, 86, 11, 129, 2322, 15, 7, 1368, 2, 605, 63, 7, 988, 2, 115, 27, 9, 9217, 11, 1091, 168, 5526, 9, 7, 2439, 90, 62, 32, 27, 6032, 448, 19, 1865, 6821, 8, 607, 5181, 2494, 2, 920, 17, 722, 448, 19, 1847, 11236, 8, 44, 210, 17, 1201, 19, 8728, 40651, 17, 756, 19, 2403, 19040, 6, 2470, 21618, 81, 487, 34, 1, 626, 478, 616, 1355, 39, 38, 209, 328, 4213, 2412, 17341, 5, 11032, 24, 1, 157, 119, 4, 238, 26, 1159, 497, 121, 1393, 8284, 7143, 23539, 6375, 13, 71, 2372, 5, 1, 5492, 2, 314, 1071, 6, 7, 1277, 5, 3525, 6, 3498, 275, 810, 7, 1178, 5, 11032, 39, 16317, 38, 5492, 11, 406, 20, 7, 2476, 589, 5, 38898, 2, 2567, 2, 71, 2, 8, 31, 11744, 560, 545, 4, 13, 473, 449, 2, 532, 4932, 37329, 38899, 1184, 11032, 11, 7, 7814, 2681, 3816, 6, 7, 3146, 9022, 5, 1, 2195, 5, 785, 8, 2741, 20, 2068, 8, 1, 314, 2874, 177, 1, 123, 3, 12, 97, 631, 3137, 2, 55, 5703, 4, 7063, 1, 1756, 5, 895, 24, 2183, 4, 4002, 1, 31649, 2342, 1511, 19, 11032, 5546, 13, 1, 2626, 2, 3744, 6, 1972, 9454, 9989, 112, 1061, 1, 6365, 314, 2531, 177, 1, 71, 6, 238, 62, 781, 1, 350, 3516, 972, 2, 55, 30, 57, 10965, 24, 675, 3805, 368, 1719, 7, 350, 12415, 8229, 6150, 4213, 2412, 80, 3383, 106, 9681, 5, 71, 11032, 23, 13, 1, 308, 2, 117, 4, 3525, 6160, 275, 24, 1, 5739, 3, 12, 180, 5492, 5527, 387, 5, 1, 33664, 2, 4596, 20, 48, 63, 51, 19555, 106, 2, 20, 297, 390, 1159, 497, 507, 639, 5, 238, 3, 12, 3812, 1599, 13, 71, 11032, 2372, 13, 289, 2, 3498, 275, 810], [8, 8459, 5, 47, 4094, 31, 303, 8, 7491, 2, 1, 3982, 7492, 1186, 4, 7023, 7, 529, 5, 98, 1401, 2844, 6, 575, 833, 4, 3889, 1, 1654, 439, 2844, 248, 234, 737, 11, 99, 8, 1580, 6, 14, 42, 286, 197, 897, 449, 2, 608, 128, 14281, 5, 56, 1697, 170, 333, 713, 2, 307, 31, 11, 7, 9099, 5, 3, 28446, 3, 31650, 3, 10829, 2148, 3, 100, 439, 8, 127259, 2, 181, 2769, 6, 10158, 4, 202, 8175, 6, 7552, 3878, 18, 2148, 8, 96516, 1, 100, 439, 8, 2847, 242, 6, 1, 586, 8, 1, 123, 39, 70, 2455, 6, 1, 71, 38, 9, 30, 7, 5510, 18, 2148, 3, 927, 600, 2, 684], [32, 6769, 16, 10705, 81, 11422, 162, 175, 751, 2, 1, 1769, 5, 3, 18809, 3, 30, 99, 2834, 4179, 8, 1, 607, 2, 127260, 16, 1, 4363, 5, 5430, 32, 89, 9100, 2601, 127261, 2, 33, 9100, 1093, 15, 147, 2, 60, 426, 1, 54062, 5583, 78, 1764, 1, 734, 5, 18809, 11, 3890, 2, 33, 14, 8959, 7, 3704, 5, 3022, 55, 11, 13836, 16, 3, 2673, 3, 6, 55, 11, 2, 8, 326, 2, 1, 3141, 5, 65, 1, 1374, 4796, 4, 835, 505, 5482, 23, 2, 666, 440, 149, 3, 12, 769, 2, 1652, 476, 33, 1, 16486, 100, 1125, 138, 7, 1154, 4, 17913, 1205, 6, 41, 62, 27, 5182, 9, 1, 206, 8, 240, 46, 32, 2237, 1, 338, 5, 456, 2243, 13112, 605, 2, 1, 638, 5, 58367, 4451, 23141, 6, 42557, 9327, 46, 27, 77, 248, 9, 14, 46, 130, 3089, 11237, 3, 12, 96517, 23142, 6, 96517, 81097, 1083, 1, 173, 35980, 5, 3879, 505, 5482, 46, 92, 476, 4, 362, 1, 3879, 5, 1, 175, 483, 146, 9177, 133, 15, 586, 1114, 17, 605, 2, 14, 46, 12507, 60, 2392, 20, 175, 6958, 33, 5, 497, 2, 1, 102, 38900, 12750, 4, 505, 5482, 11, 9, 14, 13025, 1, 4451, 16146, 5, 172, 1114, 2, 6, 31, 11, 7, 2155, 12750, 2, 1216, 9, 172, 19041, 6, 206, 12948, 1702, 9, 1, 148, 206, 264, 11, 32, 1724, 4, 27, 7, 1464, 177, 97, 456, 4451, 4310, 2, 33, 605, 177, 97, 1227, 10, 269, 50, 202, 4479, 10, 1, 3689, 5, 204, 2568, 45, 62, 5041, 7, 13113, 1194, 43, 1772, 2, 1, 1986, 1049, 2, 33, 95, 7, 3700, 2, 40, 291, 5, 2532, 46, 32, 8344, 1, 326, 9, 40, 5331, 11, 65, 29921, 40, 1358, 443, 3, 12, 2473, 31, 8960, 2, 6, 139, 989, 7, 2714, 555, 34, 92, 505, 5482, 4020, 14, 3, 1, 1250, 11, 78, 505, 5482, 115, 1652, 6393, 1, 326, 9, 1, 12949, 30, 78, 4676, 2, 33, 36, 46, 104, 14858, 1, 42557, 1558, 5, 172, 1114, 7685, 505, 5482, 23, 951, 3, 11, 836, 2187, 166, 4, 2416, 9, 69, 46, 2636, 80, 4, 366, 8, 1, 79, 206, 3, 12, 1051, 105, 5, 1949, 5, 127262, 6, 332, 3801, 3, 103, 66, 31, 53, 774, 5, 84, 2428, 5898, 50, 30, 4787, 1, 47357, 5, 1932, 715, 2, 14, 11, 35, 7628, 11599, 5526, 14, 11, 48, 300, 9, 505, 5482, 46, 2939, 97, 3513, 5, 15700, 1093, 3, 65, 37, 46, 415, 3, 19263, 3, 6, 3, 81098, 3, 3, 19263, 3, 8, 31, 256, 5663, 4, 1093, 10, 7, 664, 653, 1709, 11, 745, 4, 1, 79, 206, 3, 12, 1709, 133, 9, 56, 3, 12, 5825, 23, 3, 17914, 3, 8, 1093, 3, 11238, 3, 134, 27, 2966, 2277, 8, 49, 2347, 3, 14, 563, 1093, 10, 1, 664, 50, 11, 297, 300, 4, 787, 77, 15, 4, 1475, 7, 1262, 5, 56, 3, 12, 201, 206, 111, 50, 23, 5153, 134, 349, 4, 2637, 6267, 3, 12, 3, 1739, 4039, 3, 55, 1039, 4, 24004, 1, 775, 260, 5483, 500, 49, 4030, 5826, 5, 1639, 8, 7, 321, 269, 2, 6, 498, 6128, 66, 1, 5842, 144, 539, 3, 59, 316, 110, 357, 46, 1123, 2, 14, 115, 27, 16147, 4, 349, 20, 1, 505, 5482, 55, 6311, 8, 1, 233, 814, 31, 76, 1553, 8, 102, 852, 542, 1, 1968, 233, 366, 2, 33, 2054, 1, 4986, 6, 15700, 384, 1, 104, 658, 1553, 87, 26, 8206, 31, 482, 7, 9022, 5, 71045, 323, 11, 736, 105, 36, 53, 19263, 47, 5825, 43, 105, 36, 53, 543, 4, 130, 1, 850, 3294, 19, 11155, 7, 2348, 610, 81099, 50, 18, 4481, 267, 40, 958, 16487, 6804, 110, 423, 58, 2, 1, 1163, 5, 47, 290, 18, 58368], [592, 6, 397, 11, 7, 990, 521, 2, 7, 396, 5, 3584, 5, 592, 6, 397, 23, 241, 258, 169, 68, 45, 92, 592, 7, 662, 2, 6, 78, 56, 11, 575, 2, 5, 497, 2, 14, 54, 104, 130, 891, 4, 397, 2, 164, 3, 397, 6, 78, 56, 46, 26, 4, 178, 147, 9, 845, 3, 59, 2943, 1, 102, 3813, 1621, 33, 65, 54, 45, 92, 66, 64, 18, 755, 2182, 3, 45, 808, 7, 1024, 95, 31, 1766, 164, 174, 25, 922, 4, 592, 7, 8230, 662, 2, 6, 68, 25, 1038, 3, 59, 463, 4, 397, 105, 755, 803, 1, 1255, 2, 25, 304, 31, 1024, 1, 1024, 22, 34, 3, 4105, 37, 592, 116, 662, 64, 3, 12, 78, 31651, 33, 755, 18, 2182, 203, 116, 1190, 39, 7220, 38, 96518, 3380, 2, 3117, 3, 59, 5, 3178, 203, 8, 959, 112, 4, 1128, 127263, 3, 14, 18, 7, 173, 14977, 1024, 2, 33, 25, 150, 14, 67, 10, 14, 16, 97, 26499, 8, 1, 208, 37, 3197, 9, 134, 2404, 21, 28, 29, 17, 14, 3, 127264, 757, 1184, 6959], [681, 6, 4485, 2987, 1615, 11, 3120, 19, 3344, 1446, 569, 2, 33, 68, 110, 569, 23, 32, 708, 2, 6, 84, 5, 1, 165, 189, 11, 249, 10, 1134, 5254, 2, 139, 2953, 4171, 3570, 965, 247, 8, 607, 652, 6, 1675, 2859, 30, 287, 982, 13, 1, 262, 1635, 17171, 2, 6, 1, 334, 2474, 7144, 8460, 4116, 10764, 4, 17014, 11, 2408, 334, 1439, 13222, 1249, 1634, 8310, 3, 9247, 1864, 4, 2404, 14, 2, 15, 127, 216, 940, 200, 6888, 2, 6, 37, 46, 32, 789, 67, 1, 11239, 5, 189, 24, 1, 3076, 4, 1, 681, 5, 1, 2226, 8345, 2, 33, 13222, 13, 17014, 6, 8460, 11, 558, 1340, 6, 1340, 77, 2, 443, 1, 75, 5, 44, 342, 924, 49, 1446, 165, 19, 2, 152, 2, 219, 1057, 309, 4523, 2, 6, 989, 81, 1028, 4906, 4, 182, 4, 924, 1, 180, 165, 894, 1, 75, 62, 671, 435, 44, 189, 13, 1, 2226, 8345, 2, 15, 16, 1209, 48, 2824, 2, 1, 18155, 96, 1232, 2, 355, 1, 1618, 279, 4112, 142, 31, 11, 1, 614, 1439, 574, 8, 44, 342, 2, 6, 109, 1, 159, 5, 652, 62, 588, 31, 611, 2, 75, 6, 180, 189, 23, 842, 4, 1459, 31, 611, 4, 7, 180, 2953, 874, 6048, 652, 31, 6546, 343, 212, 11, 1147, 114, 192, 34, 2646, 3, 2265, 254, 2, 622, 165, 821, 5503, 160, 2, 3, 652, 697, 2, 12668, 1011, 34, 116, 2646, 4419, 165, 1232, 13, 254, 6, 1141, 622, 656, 11, 2295, 3029, 1, 1496, 9, 7, 165, 362, 54, 11240, 13, 2686, 2, 382, 6, 165, 2253, 11, 488, 33, 97, 357, 52, 1, 1277, 23, 47358, 100, 2, 14, 11, 14053, 9, 3, 44, 342, 3, 12, 1028, 4906, 11, 157, 3, 10, 411, 3, 1956, 35, 343, 212, 4797, 2, 78, 978, 11, 440, 4, 1, 4237, 781, 9, 343, 165, 1232, 26, 13, 888, 8, 593, 414, 10118, 102, 5, 44, 342, 3, 12, 4906, 2785, 1139, 656, 5, 254, 6, 1141, 622, 2114, 2, 1468, 2, 8, 44, 342, 36, 2785, 4430, 254, 656, 6, 4406, 3090, 3, 343, 1022, 9, 87, 1460, 81, 162, 330, 2, 362, 107, 2253, 6, 3695, 1, 1549, 5, 1614, 142, 165, 1232, 13, 160, 23, 1652, 13938, 19, 1, 877, 569, 23, 7, 474, 5, 485, 160, 2, 6, 68, 525, 213, 67, 2, 1, 362, 11, 736, 816, 484, 1353, 15, 7, 351, 376, 2, 43, 9861, 68, 1285, 11, 2065, 351, 343, 368, 23, 8056, 5255, 4, 111, 50, 23, 279, 147, 186, 105, 36, 12342, 7, 1497, 2869, 5, 47, 414, 4, 343, 81, 421, 162, 343, 212, 29179, 656, 5, 8497, 1139, 343, 2, 172, 16318, 6, 4406, 2, 8, 1494, 5, 20383, 5263, 81, 439, 11, 9140, 16, 35, 11156, 5, 21267, 343, 1022, 9, 41, 26, 3282, 4, 8008, 351, 1139, 656, 5, 254, 6, 1141, 622, 54, 1170, 343, 368, 6, 924, 1, 1329, 5, 857, 10, 875, 81, 13114, 343, 212, 11, 2855, 2814, 4, 81, 439, 109, 19818, 1, 102, 1496, 13, 1, 297, 9068, 284, 114, 401, 3964, 127265, 740, 11542, 669, 207, 770, 16, 627, 32, 4725, 2, 940, 6822, 2055, 827, 4, 29180, 16, 160, 569, 2, 55, 46, 633, 8, 279, 337, 8, 1, 1487, 2, 55, 563, 279, 189, 10, 125, 385, 2, 55, 563, 48, 9248, 10, 44, 5827, 33, 48, 1365, 10, 669, 2, 1048, 482, 1554, 50, 3550, 4, 85, 204, 10478, 73, 32, 3010, 11, 9, 32, 56, 618, 18, 2048, 5, 22736, 1169, 122, 6705, 160, 569, 30, 708, 669, 6, 1033, 48, 382, 8, 326, 2, 41, 26, 58, 80, 7, 883, 5, 593, 160, 569, 6, 7510, 9, 2919, 8, 1, 968, 5, 382, 2, 113, 832, 2661, 1, 4586, 326, 11, 9, 165, 2528, 539, 3, 59, 840, 382, 17, 726, 4074, 382, 6, 8, 436, 4, 26, 726, 2, 69, 207, 189, 8, 47, 5957, 244, 2, 1957, 23, 10289, 1, 633, 3, 78, 726, 78, 726, 563, 78, 160, 6, 31, 286, 9101, 325, 669, 9, 3318, 13, 325, 770, 7442, 1554, 2866, 823, 4, 557, 2661, 2, 122, 1, 642, 737, 11, 742, 2, 382, 23, 841, 6, 4304, 23, 1146, 77, 66, 1, 647, 827, 4, 7443, 405, 247, 2, 37, 2013, 82, 1279, 72, 7, 151, 4, 362, 1957, 490, 2, 82, 3350, 3396, 75, 313, 2, 6693, 1209, 4, 1, 574, 2, 32, 10251, 14, 6111, 2, 164, 224, 4, 1, 692, 52, 2205, 1, 1952, 7145, 165, 3, 55, 2, 19, 1, 151, 2, 37, 226, 3, 18, 35, 692, 52, 228, 3076, 1522, 7079, 3, 12, 1479, 7, 1851, 387, 391, 500, 1, 3444, 165, 769, 1181, 8, 1, 79, 692, 1151, 2, 81100, 46, 27, 1209, 676, 48, 382, 4, 49, 3129, 103, 8, 1, 615, 5, 1, 12259, 50396, 77, 50, 3, 12, 164, 34, 7079, 3, 12, 6, 81100, 2, 43, 1, 647, 3, 6873, 5264, 652, 171, 116, 47359, 8461, 72, 6, 13223, 14, 443, 203, 120, 31, 1910, 37, 3, 430, 1730, 4, 872, 4105, 10, 7, 160, 9, 18, 1341, 2, 3451, 2, 13, 1, 5493, 5, 1081, 2720, 77, 84, 69, 87, 130, 7, 2815, 315, 39, 9, 11, 166, 38, 72, 5, 160, 3, 2187, 3, 12508, 6, 197, 38901, 235, 6, 2, 845, 3, 59, 14, 8406, 4, 283, 1, 1863, 1787, 224, 4, 85, 5908, 2681, 197, 521, 41, 25937, 3061, 2, 43, 49, 14619, 87, 27, 5781, 13, 1, 14978, 591, 85, 60, 5, 1543, 3, 12, 9500, 205, 4, 648, 6889, 96519, 10650, 50, 3, 12, 793, 1, 17342, 2, 1536, 96520, 3, 192, 34, 3, 17342, 3345, 13, 6924, 2, 14744, 30781, 2355, 3, 34, 41, 1502, 231, 116, 2646, 5, 2352, 764, 13, 1, 866, 1368, 1, 136, 9, 1, 162, 12509, 5, 220, 827, 4, 1291, 1400, 3268, 785, 13, 21619, 30781, 462, 11, 172, 3444, 6, 5673, 1468, 2, 1, 17342, 215, 32, 345, 65, 1, 125, 2465, 836, 16, 550, 7, 1275, 30, 57, 5003, 4, 959, 5, 1, 91, 5, 4670, 1345, 110, 17915, 26, 4787, 1, 8889, 11, 2277, 3, 44, 342, 11361, 1, 17915, 5, 31, 2342, 10, 1, 267, 219, 91, 2, 6, 99, 1, 17342, 466, 4, 3517, 1, 17915, 88, 1, 2360, 6231, 398, 33, 1, 17342, 11, 32, 104, 5674, 1, 125, 79, 2090, 446, 26, 440, 67, 13, 30781, 462, 10830, 1799, 504, 17915, 8, 851, 8, 897, 2, 3084, 148, 949, 1, 2646, 3, 1292, 30781, 2325, 2, 3, 6, 2210, 31, 76, 1558, 239, 72, 1, 17342, 3, 12, 6112, 644, 5, 1, 312, 46, 31, 14620, 154, 3, 66, 17915, 23, 6450, 4, 48, 10024, 2, 6, 5255, 2, 462, 2, 1129, 1, 388, 10, 1, 17342, 11, 255, 482, 66, 1, 17342, 1102, 4, 1291, 3268, 189, 13, 31, 1671, 5, 462, 2, 8407, 2565, 24958, 6, 786, 7894, 6, 14505, 1634, 8109, 2, 2496, 4798, 8763, 6, 1865, 9501, 134, 366, 4, 7377, 802, 10, 1, 1034, 30781, 462, 312, 139, 2, 1129, 2, 1, 17342, 259, 458, 4, 1390, 7, 456, 340, 5, 838, 5899, 14979, 69, 10, 2681, 2597, 5, 44, 342, 652, 7, 364, 257, 14621, 4, 45, 2, 9455, 58369, 192, 34, 116, 692, 3, 4635, 5, 11033, 6477, 11893, 3, 34, 128, 1086, 2, 9455, 1476, 58369, 2, 2471, 39, 24959, 38, 11, 7, 7175, 5, 1, 11033, 6477, 416, 25, 18, 1, 533, 603, 5, 1, 761, 4095, 5, 1, 44783, 5765, 10119, 11894, 20, 1, 96, 6, 5983, 129, 21620, 19, 7, 2159, 2687, 4552, 1814, 37330, 138, 4, 40, 164, 52, 219, 1619, 186, 1, 1005, 2, 2880, 807, 11033, 6477, 25, 30, 89, 1288, 2, 16, 127266, 127267, 2, 11895, 2, 6, 949, 7, 643, 5, 40, 19042, 3983, 3, 24, 63858, 2494, 4, 11033, 71046, 3, 14, 3, 12, 35, 31652, 6, 10706, 522, 10, 836, 2231, 8, 1, 416, 11034, 11035, 58369, 652, 547, 39, 5457, 38, 4, 7, 998, 571, 45, 15551, 127268, 127, 7, 2699, 405, 13, 448, 1, 251, 3388, 848, 174, 8, 652, 2, 317, 7, 1131, 5, 270, 359, 2, 1, 44, 210, 196, 3, 786, 601, 127, 7, 434, 9, 460, 7470, 9, 1, 17343, 153, 23, 472, 4, 558, 1, 7815, 3, 12, 3893, 4, 202, 4230, 2, 6, 601, 1713, 72, 9, 1, 936, 3571, 11, 288, 504, 127269, 10, 47, 182, 1, 1853, 196, 73, 58, 7, 1361, 39, 13, 2082, 1656, 38, 13, 1, 559, 202, 5, 4230, 19, 1, 740, 884, 413, 2300, 50, 23, 377, 16, 7, 3388, 9, 7160, 8, 1, 14859, 5, 7, 153, 662, 6, 215, 20932, 357, 95, 4214, 138, 7, 17523, 50, 259, 13939, 2300, 2, 15, 147, 15, 153, 2, 8, 3487, 29922, 3, 398, 2, 7064, 1305, 24960, 10, 40, 434, 3, 127270, 127271, 652, 19, 3863, 43, 19, 24005, 2, 14, 3, 12, 1331, 4, 226, 10025, 11, 355, 7, 1301, 451, 19, 2092, 49, 4135, 14381, 2218, 2219, 6, 9635, 9, 387, 4, 758, 6, 79, 489, 3504, 9, 3, 12, 65, 102, 4152, 8, 79, 119, 26, 568, 2, 16, 1, 231, 5, 75, 2256, 1, 474, 5, 54063, 2218, 2219, 2519, 4, 7, 7874, 10, 1, 219, 83, 5, 770, 50, 4355, 4, 226, 8, 578, 9, 3, 12, 4237, 4, 1, 1933, 83, 50, 226, 19, 3863, 43, 602, 317, 84, 325, 1270, 23, 28447, 1, 125, 2558, 858, 4, 381, 1, 2219, 505, 78, 597, 112, 132, 14, 525, 1, 1062, 5, 114, 37, 862, 1, 6412, 46, 828, 10025, 4, 3301, 31, 5201, 474, 3361, 6, 5272, 1, 13422, 4, 818, 7176, 7286, 13, 1, 14054, 3, 12031, 1098, 4920, 27108, 652, 1532, 4, 111, 50, 92, 1, 47360]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain_seq[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rvn7NZ_iWvDy"
   },
   "outputs": [],
   "source": [
    "word2index = toki.word_index\n",
    "word2index['PAD'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mb3fIeqnWvD2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD\n"
     ]
    }
   ],
   "source": [
    "index2word = toki.index_word\n",
    "index2word[0] = 'PAD'\n",
    "print(index2word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQfOn7v3WvD5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3336 605.8469037732443\n"
     ]
    }
   ],
   "source": [
    "#get max length of words\n",
    "\n",
    "lens = [len(text) for text in Xtrain]\n",
    "\n",
    "max_len = max(lens)\n",
    "mean_len = np.mean(lens)\n",
    "\n",
    "print(max_len, mean_len)\n",
    "\n",
    "max_len = int(mean_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLSlD2KSWvD9"
   },
   "outputs": [],
   "source": [
    "#pre-pad the tweets with value 0\n",
    "# that is prepadding (Louis so you understand as well)\n",
    "Xtrain_pad = pad_sequences(Xtrain_seq, maxlen = max_len)\n",
    "Xtest_pad = pad_sequences(Xtest_seq, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0EbZrlOWvEA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36486     False\n",
       "189129     True\n",
       "95226     False\n",
       "195710     True\n",
       "32290     False\n",
       "Name: hyperp, dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwsprURhWvEE"
   },
   "outputs": [],
   "source": [
    "label_dict_bin = {\n",
    "    'True':1,\n",
    "    'False':0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYe73g-nWvEH"
   },
   "outputs": [],
   "source": [
    "Ytrain = [label_dict_bin[str(label)] for label in Ytrain]\n",
    "Ytest = [label_dict_bin[str(label)] for label in Ytest] \n",
    "\n",
    "# this is now a list of numbers (instead of 'neutral' etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCX_ktnIWvEL"
   },
   "outputs": [],
   "source": [
    "Ytrain_cat = np.asarray([to_categorical(label, num_classes = 2) for label in Ytrain])\n",
    "Ytest_cat = np.asarray([to_categorical(label, num_classes = 2) for label in Ytest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9F_Hb2emWvEO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_cat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFn4e9NsWvES"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (38773, 605)\n",
      "Shape of label tensor: (38773, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', Xtrain_pad.shape)\n",
    "print('Shape of label tensor:', Ytrain_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ny9O1CCWvEV"
   },
   "source": [
    "### Prepare the Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aMXU3exWvEW"
   },
   "outputs": [],
   "source": [
    "embeddings = Word2Vec.load('model_all.bin')\n",
    "embed_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FV5k0356WvEZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#make an index2embedding dict\n",
    "# TODO: change to word embeddings from Spanish and English\n",
    "\n",
    "index2emb = dict()\n",
    "w = filter(lambda x: x in word2index.keys(), list(embeddings.wv.vocab))\n",
    "\n",
    "for i, w in index2word.items():\n",
    "    try:\n",
    "        embed = embeddings[w]\n",
    "    except KeyError:\n",
    "        embed = np.zeros(embed_len)\n",
    "        #embed = embeddings.most_similar(positive=w)\n",
    "    index2emb[i] = embed\n",
    "\n",
    "    \n",
    "#w = filter(lambda x: x in model.vocab, list(model.wv.vocab))\n",
    "#print model.most_similar(positive=w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRT4gSxcWvEc"
   },
   "outputs": [],
   "source": [
    "#compute embedding matrix\n",
    "\n",
    "embedding_matrix = np.zeros((len(word2index) + 1, embed_len))\n",
    "for word, i in word2index.items():\n",
    "    embedding_vector = index2emb[i]\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46WMiWTgWvEf"
   },
   "outputs": [],
   "source": [
    "#load embedding matrix into embedding layer\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(len(word2index) + 1,\n",
    "                            embed_len,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r7rdB0cnWvEi"
   },
   "source": [
    "### Building the classifier - FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrC_iXLNWvEk"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "lr = 0.001\n",
    "batch = 512\n",
    "#embed_len = 100\n",
    "activation = 'relu'\n",
    "activation_output = 'softmax'\n",
    "loss_function = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2aZ89JiBWvEo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 605)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 605, 100)          24530600  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 60500)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               12100200  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 36,643,794\n",
      "Trainable params: 12,113,194\n",
      "Non-trainable params: 24,530,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "flat = Flatten()(embedded_sequences)\n",
    "\n",
    "output_1 = Dense(200, activation='tanh')(flat)\n",
    "#drop = Dropout(0.4)(output_1)\n",
    "output_2 = Dense(64, activation='relu')(output_1)\n",
    "predictions = Dense(2, activation=activation_output)(output_2)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=predictions)\n",
    "\n",
    "optimizer = Adam(lr = lr)\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50Z2bbm4WvEs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "38773/38773 [==============================] - 24s 621us/step - loss: 0.6531 - accuracy: 0.6784\n",
      "Epoch 2/20\n",
      "38773/38773 [==============================] - 25s 644us/step - loss: 0.4183 - accuracy: 0.8095\n",
      "Epoch 3/20\n",
      "38773/38773 [==============================] - 24s 616us/step - loss: 0.3213 - accuracy: 0.8613\n",
      "Epoch 4/20\n",
      "38773/38773 [==============================] - 24s 611us/step - loss: 0.2608 - accuracy: 0.8933\n",
      "Epoch 5/20\n",
      "38773/38773 [==============================] - 24s 613us/step - loss: 0.2157 - accuracy: 0.9140\n",
      "Epoch 6/20\n",
      "38773/38773 [==============================] - 24s 616us/step - loss: 0.1884 - accuracy: 0.9263\n",
      "Epoch 7/20\n",
      "38773/38773 [==============================] - 24s 613us/step - loss: 0.1675 - accuracy: 0.9329\n",
      "Epoch 8/20\n",
      "38773/38773 [==============================] - 24s 618us/step - loss: 0.1444 - accuracy: 0.9437\n",
      "Epoch 9/20\n",
      "38773/38773 [==============================] - 24s 613us/step - loss: 0.1288 - accuracy: 0.9496\n",
      "Epoch 10/20\n",
      "38773/38773 [==============================] - 24s 616us/step - loss: 0.1172 - accuracy: 0.9557\n",
      "Epoch 11/20\n",
      "38773/38773 [==============================] - 25s 641us/step - loss: 0.1058 - accuracy: 0.9612\n",
      "Epoch 12/20\n",
      "38773/38773 [==============================] - 25s 648us/step - loss: 0.1078 - accuracy: 0.9588\n",
      "Epoch 13/20\n",
      "38773/38773 [==============================] - 24s 616us/step - loss: 0.1244 - accuracy: 0.9510\n",
      "Epoch 14/20\n",
      "38773/38773 [==============================] - 24s 626us/step - loss: 0.1243 - accuracy: 0.9513\n",
      "Epoch 15/20\n",
      "38773/38773 [==============================] - 24s 615us/step - loss: 0.1094 - accuracy: 0.9581\n",
      "Epoch 16/20\n",
      "38773/38773 [==============================] - 20s 509us/step - loss: 0.0913 - accuracy: 0.9654\n",
      "Epoch 17/20\n",
      "38773/38773 [==============================] - 20s 504us/step - loss: 0.0746 - accuracy: 0.9715\n",
      "Epoch 18/20\n",
      "38773/38773 [==============================] - 20s 509us/step - loss: 0.0738 - accuracy: 0.9729\n",
      "Epoch 19/20\n",
      "38773/38773 [==============================] - 20s 510us/step - loss: 0.0707 - accuracy: 0.9748\n",
      "Epoch 20/20\n",
      "38773/38773 [==============================] - 20s 509us/step - loss: 0.0703 - accuracy: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4a1ed87be0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain_pad, Ytrain_cat, batch_size = batch, epochs=epochs, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hm13g7AWvEv"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(Xtest_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrojzAtiWvEx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.74      4813\n",
      "           1       0.73      0.78      0.76      4881\n",
      "\n",
      "    accuracy                           0.75      9694\n",
      "   macro avg       0.75      0.75      0.75      9694\n",
      "weighted avg       0.75      0.75      0.75      9694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(predictions, axis=1)\n",
    "Ytest_converted = np.argmax(Ytest_cat, axis=1)\n",
    "\n",
    "print(classification_report(Ytest_converted, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "embed_lstm.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
