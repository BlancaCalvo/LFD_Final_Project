{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13ymSU11WvDa"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2fl8SDXXT00"
   },
   "outputs": [],
   "source": [
    "# this is for google colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqaHYo_UWvDc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# tool_path = \"/content/drive/Shared drives/Shared Task SentiMix/tools\"\n",
    "\n",
    "# import tools\n",
    "\n",
    "# import tools.baseline as bt\n",
    "# import tools.data as data_tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding, Bidirectional, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from keras.optimizers import Adam\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from keras.layers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(corpus_file):\n",
    "    \"\"\"read input document and return the textual articles\n",
    "    and either the bias or hyperpartisan label\"\"\"\n",
    "\n",
    "    with open(corpus_file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    documents = data.sentences\n",
    "    labels_bin = data.hyperp\n",
    "    labels_mult = data.bias\n",
    "\n",
    "\n",
    "    return documents, labels_bin, labels_mult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y_bin, Y_mult = read_corpus('tokenised_full.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain_bin, Ytest_bin, Ytrain_mult, Ytest_mult = train_test_split(X, \n",
    "                                                Y_bin, \n",
    "                                                Y_mult, \n",
    "                                                test_size = 0.2,\n",
    "                                                stratify = Y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuAJJFJmWvDm"
   },
   "outputs": [],
   "source": [
    "toki = Tokenizer()\n",
    "toki.fit_on_texts(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4mEdrNxWvDq"
   },
   "outputs": [],
   "source": [
    "Xtrain_seq = toki.texts_to_sequences(Xtrain)\n",
    "Xtest_seq = toki.texts_to_sequences(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fLPNbFAWvDt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19, 3864, 6460, 2197, 3402, 788, 1, 8987, 10, 1422, 8, 1, 161, 119, 6, 196, 1, 122, 23, 35, 5059, 5, 6461, 52, 1, 85, 253, 3, 12, 388, 2475, 2, 55, 7775, 124, 776, 10, 1422, 2, 684, 6, 555, 478, 6, 1626, 4, 354, 1, 1625, 388, 19, 51, 4582, 27071, 181, 776, 10, 955, 3408, 5, 478, 11, 2305, 2738, 64, 23, 5094, 2, 10, 2241, 2, 9, 552, 220, 190, 3, 59, 183, 15, 7, 3003, 107, 36, 1334, 7, 376, 280, 5, 69, 42, 1, 8332, 10, 55, 11, 2249, 4, 1744, 261, 1410, 107, 102, 1153, 23, 916, 6, 655, 8, 1, 334, 373, 66, 45, 655, 8, 926, 42, 79, 127388, 1268, 5, 1, 114, 2, 6, 116, 310, 11, 3715, 7, 950, 2, 45, 115, 26, 11626, 20, 1, 804, 5, 1, 3655, 3219, 14, 11, 1, 164, 1179, 5, 214, 9, 11, 776, 1, 1147, 10, 7, 4617, 887, 45, 1382, 1, 1462, 124, 1341, 52, 1, 7084, 6189, 8, 600, 1828, 8, 20065, 50, 11, 387, 13, 7, 4617, 3, 1, 114, 108, 6, 5282, 8, 1, 114, 259, 2, 4617, 745, 11, 7, 127389, 2441, 33, 3, 5, 1, 51, 4123, 125, 9, 659, 114, 4617, 478, 6, 745, 3004, 2, 4515, 94, 540, 24, 4617, 242, 2, 3328, 94, 24, 1704, 2, 6, 958, 94, 24, 714, 31601, 3, 15, 10, 555, 2, 5178, 102, 460, 997, 13, 70940, 5, 7, 96580, 4274, 796, 3774, 2, 1024, 5, 1, 1149, 23, 460, 38867, 19, 24004, 478, 2, 6, 1, 5178, 262, 8, 10, 1, 93, 4983, 6658, 7315, 2, 3, 1, 1781, 2698, 9, 646, 7591, 80978, 94, 683, 23, 1306, 13, 38, 6, 112, 5, 60, 1321, 1490, 37, 2, 24, 1, 3507, 2, 4, 1, 1090, 2, 4, 6659, 2, 4, 1, 1783, 11236, 2, 54, 60, 1516, 42, 10135, 2067, 19, 108, 17338, 3, 85, 3, 12, 813, 46, 32, 104, 128, 114, 3068, 6, 44705, 1, 6278, 5662, 9, 128, 80, 732, 49, 8424, 2, 25, 46, 2760, 114, 8, 4854, 1, 557, 25, 23136, 746, 4, 4075, 3, 114, 10439, 45, 190, 3, 59, 3302, 16, 1, 1051, 5, 1, 122, 19, 1138, 35, 2265, 51, 4582, 125, 4, 1, 234, 6, 2412, 2123, 478, 6, 745, 38, 2499, 21, 192, 17, 674, 37, 776, 1, 164, 1422, 1312, 15407, 9, 246, 2, 373, 696, 6, 1549, 23, 1542, 3229, 108, 189, 88, 2499, 21, 192, 17, 674, 2, 15, 148, 15, 1505, 8, 1422, 563, 6, 1, 639, 5, 9169, 1422, 6, 3357, 451, 85, 2, 8, 2539, 2, 860, 405, 114, 563, 4, 14365, 11237, 2, 50, 11427, 2070, 10099, 563, 6, 828, 319, 1000, 67, 8, 8486, 3086, 794, 1, 47305, 1922, 2, 3, 9051, 304, 505, 14, 490, 9, 110, 1, 161, 119, 1091, 4, 592, 8, 7, 2687, 5, 6914, 2, 14, 4324, 8, 35, 1554, 80979, 122, 10, 12, 21, 192, 17, 4201, 9, 19022, 196, 1, 2758, 6, 197, 5, 2147, 6, 555, 117, 4, 9051, 304, 2, 246, 11, 100, 1, 6769, 11490, 5, 2499, 21, 192, 17, 674, 2, 3619, 10, 445, 82, 5, 334, 2499, 21, 192, 17, 674, 15, 880, 4, 1, 161, 119, 2, 55, 1337, 10, 1682, 82, 246, 11, 288, 1411, 47, 735, 21009, 286, 49, 63, 1, 161, 119, 2, 769, 2499, 21, 192, 17, 674, 440, 363, 445, 82, 7, 76, 257, 76, 24, 1945, 4, 687, 9, 364, 5, 354, 286, 37366, 9, 5, 1, 114, 8, 112, 90, 2, 6, 100, 85, 462, 828, 114, 4, 7775, 440, 2, 110, 1, 680, 210, 13, 1505, 8, 6278, 3774, 1, 166, 68, 246, 96581, 1, 114, 13, 478, 6, 745, 3004, 11, 89, 196, 1, 3604, 2, 6, 85, 3, 12, 388, 53, 766, 14, 103, 49, 1033, 8, 83, 866, 2, 246, 11, 47306, 20, 80, 6035, 1, 334, 343, 5, 1, 114, 8, 6477, 1654, 3, 1777, 94, 1, 334, 343, 5, 246, 8, 6477, 1654, 3, 1682, 94, 230, 491, 539, 5, 60, 1, 10000, 3, 12, 3675, 4340, 176, 76, 8, 246, 23, 8, 1422, 6, 3357, 8, 1, 114, 14, 11, 104, 30705, 110, 246, 6, 373, 696, 13019, 7402, 67, 108, 2499, 21, 192, 17, 674, 1633, 2, 1, 2117, 203, 357, 8, 1, 114, 30, 57, 2412, 2123, 8302, 3, 8, 687, 2, 108, 3152, 2499, 21, 192, 17, 674, 5087, 10, 1682, 82, 5, 583, 71, 2499, 21, 192, 17, 674, 6, 18, 1, 627, 4802, 38, 3656, 82, 37, 5, 60, 71, 1781, 478, 3, 3, 9051, 752, 9, 181, 587, 8, 173, 3187, 6, 160, 1001, 2499, 21, 192, 17, 674, 30, 1072, 8, 255, 90, 121, 1, 359, 2054, 2, 2785, 2, 396, 2499, 21, 192, 17, 674, 250, 3004, 3, 859, 5, 1, 2051, 5, 71, 3858, 3, 30, 32, 1908, 16129, 250, 8, 583, 71, 2499, 21, 192, 17, 674, 8224, 104, 5869, 82, 3004, 81, 1, 127390, 704, 2, 580, 1, 3424, 82, 735, 423, 10, 71, 3858, 1, 122, 46, 32, 1145, 143, 110, 85, 5516, 1, 442, 3, 12, 1422, 6, 555, 88, 4221, 10229, 8, 332, 2, 66, 85, 1314, 40, 150, 13, 1, 1422, 388, 2, 130, 2660, 4, 319, 11, 4, 458, 5696, 680, 96582, 85, 11, 2123, 189, 10, 9, 2, 251], [6495, 1552, 27, 254, 9, 19, 512, 2744, 25408, 8988, 16, 244, 231, 451, 544, 8, 7, 18787, 9170, 6, 35, 3144, 8, 48, 50263, 3, 97, 8988, 2, 303, 6533, 52, 2454, 1294, 6, 2448, 597, 2, 917, 5266, 8, 7, 492, 6, 2079, 191, 5, 13517, 451, 81, 35, 3187, 10136, 2, 3, 495, 7104, 17339, 2, 35, 2554, 1328, 5, 8303, 20, 6495, 2, 482, 16, 40, 2607, 81, 7, 105, 244, 231, 451, 1275, 72, 257, 959, 76, 2, 14995, 10, 726, 763, 42, 1, 3209, 2, 117, 4, 1, 697, 8, 1, 699, 5, 5697, 1422, 460, 1, 938, 11, 21010, 8, 1, 556, 2, 1552, 13113, 1, 768, 5, 97, 2689, 5, 597, 8988, 13, 127391, 451, 8, 895, 244, 794, 56, 2937, 882, 1, 745, 5, 7, 3, 250, 9170, 3, 6, 1, 79, 7, 3, 901, 5, 21298, 3, 1, 2937, 2096, 7, 127392, 8011, 2, 55, 18, 1484, 4, 243, 451, 11765, 111, 50263, 87, 243, 99, 6086, 3946, 298, 2274, 173, 1, 8988, 54, 1896, 20, 1735, 451, 2, 660, 916, 7025, 1, 478, 4943, 868, 8, 451, 3, 7970, 8, 1681, 3187, 5757, 1, 544, 810, 9, 281, 451, 20, 714, 10, 4409, 72, 38, 6317, 5, 1, 5990, 37, 2, 173, 8988, 917, 127393, 6, 725, 1, 364, 20, 55, 1, 451, 3567, 58234, 8, 303, 493, 19, 11238, 1435, 457, 1, 4153, 947, 8303, 1552, 485, 96583, 2, 80980, 6127, 2, 2344, 1742, 6, 1328, 9015, 127394, 2, 60, 5, 6495, 384, 2, 6, 485, 44706, 2, 2554, 1328, 5, 8303, 20, 1, 384, 5, 612, 2, 3676, 56, 21, 28, 29, 17, 622, 11, 111, 56, 5, 1, 250, 9170, 7485, 58, 451, 529, 35, 697, 4837, 1, 2772, 3, 12, 1141, 4, 1319, 6, 103, 22333, 779, 15, 7, 6213, 5, 619, 182, 6, 19546, 3187, 3425, 1, 1260, 18, 4, 841, 451, 36, 27, 1, 591, 4, 402, 49, 7026, 149, 556, 6, 1644, 2, 6, 9, 15975, 10539, 91, 32, 3814, 1390, 591, 96583, 22, 2, 3, 66, 80, 785, 2, 25408, 1941, 62, 243, 451, 183, 231, 15, 7, 347, 123, 36, 62, 1319, 48, 11627, 6, 402, 1, 635, 5, 575, 36, 213, 4, 26, 2, 6, 66, 9, 293, 8, 2768, 505, 451, 49, 5232, 6, 1507, 2, 138, 14, 749, 299, 9, 64, 23, 113, 2049, 8, 1, 5542, 4, 1565, 109, 2840, 4, 229, 3464, 20066, 3, 1, 623, 10, 563, 478, 9, 12690, 3, 42, 127395, 2, 35, 3260, 478, 392, 20, 6495, 384, 3, 11, 387, 796, 109, 2274, 19, 5344, 16, 1250, 4, 2494, 6, 2750, 127396, 2053, 4, 243, 451, 2135, 49, 23565, 50264], [1857, 5, 1823, 2705, 3, 12, 2072, 23, 1551, 761, 52, 241, 1, 146, 124, 534, 3, 1025, 259, 3, 55, 10, 175, 908, 30, 3627, 9, 1557, 14, 14870, 8, 390, 2956, 168, 7, 490, 6605, 2087, 3, 430, 3, 59, 553, 9848, 2128, 2053, 19, 1, 475, 11428, 2128, 1529, 9, 54, 98, 1232, 8, 687, 6, 55, 2934, 8, 1063, 181, 1360, 8, 737, 1823, 2705, 30, 57, 56, 5, 6318, 3, 627, 2534, 8, 255, 90, 117, 4, 3440, 263, 1155, 2, 6318, 3, 51, 17922, 27716, 2091, 8, 1, 284, 11, 47, 1349, 615, 1352, 70, 646, 2, 8563, 6, 2112, 7, 772, 5, 1, 6318, 434, 3, 75, 7934, 407, 10613, 3, 145, 14, 3, 12, 4285, 4, 981, 6318, 4, 26, 7, 693, 4489, 8, 1055, 4, 60, 47, 79, 4261, 110, 1, 1823, 2705, 2091, 115, 1068, 492, 2, 14, 2565, 4, 6317, 5, 268, 82, 5, 6318, 3, 51, 44707, 125, 2181, 8, 7, 475, 1308, 5825, 187, 399, 31, 264, 2, 6318, 18, 73, 3958, 13, 1, 3549, 9, 113, 1798, 6, 20067, 73, 430, 3, 59, 91, 48, 541, 14610, 3, 14, 3, 12, 361, 9, 135, 27, 57, 1848, 3, 14, 10056, 211, 1, 1889, 483, 13, 15, 235, 15, 14, 127, 2, 3, 217, 5475, 714, 605, 11695, 31602, 144, 1, 1591, 1, 1823, 2705, 2072, 882, 284, 534, 5884, 67, 4, 386, 105, 44, 1337, 6, 488, 2109, 8, 1, 636, 5, 755, 1, 534, 2113, 12841, 13, 111, 113, 44, 34774, 24, 1651, 945, 6445, 36, 54, 369, 4, 120, 6, 58, 263, 4015, 4, 846, 1337, 248, 755, 3, 2147, 1823, 2705, 712, 407, 14611, 4211, 31, 850, 70, 181, 2221, 7718, 1, 101, 51, 12283, 105, 8, 737, 2, 50265, 51, 4132, 105, 8, 6319, 25, 2515, 4, 128, 1, 101, 73, 22, 9, 49, 63, 3696, 534, 50, 949, 1, 8585, 1337, 58, 57, 1442, 510, 1, 546, 595, 5, 6318, 1227, 19, 10613, 6, 1247, 372, 1562, 2, 443, 156, 9, 2001, 11, 4784, 107, 5, 6318, 3, 235, 426, 5, 3243, 693, 3742, 1239, 8, 1, 3914, 2, 6318, 573, 24429, 7, 710, 5, 3, 996, 3, 220, 16, 515, 5, 1341, 3, 4559, 24, 2514, 8, 1007, 9, 430, 3, 59, 1089, 1, 1421, 42, 54, 8333, 4, 40614, 1214, 2, 133, 15, 38868, 6446, 42, 434, 324, 2, 42, 32, 528, 3984, 6, 1977, 3250, 16, 1, 12214, 36, 9526, 31, 30, 586, 4, 164, 706, 5, 6318, 2, 1, 627, 71, 108, 1584, 659, 8, 2006, 2, 1, 44, 204, 201, 973, 35, 1956, 238, 1810, 81, 111, 619, 6318, 135, 210, 70, 133, 4368, 15, 2480, 2, 29884, 2, 1, 44, 204, 226, 793, 6, 58235, 22703, 4334, 14, 586, 4, 1, 10976, 5, 6318, 434, 92, 3921, 96584, 7, 449, 545, 2, 96584, 18, 1023, 2388, 52, 167, 70, 65, 25, 812, 15, 2417, 228, 6, 916, 3005, 19, 693, 5192, 34, 25, 73, 917, 13020, 68, 4145, 6318, 4, 6915, 1078, 3181, 3413, 6, 554, 6318, 4, 227, 7, 214, 648, 830, 1588, 1688, 9, 889, 20, 1, 96, 2, 31, 18, 8768, 15, 35, 127397, 3368, 19, 16660, 434, 7776, 151, 19, 233, 942, 3578, 3510, 34, 9, 862, 18, 38869, 19, 1, 434, 3, 12, 1070, 8, 1478, 68, 14, 6, 79, 523, 4059, 12120, 2131, 81, 47, 455, 4, 37367, 1, 2422, 5, 712, 2194, 36029, 19, 1799, 132, 4, 127398, 40, 226, 1479, 4, 7, 49, 4455, 340, 8, 96, 8, 685, 6, 513, 2, 6318, 9767, 6, 1397, 6077, 8, 554, 646, 3, 12, 434, 4, 26, 49, 7592, 6, 500, 4, 1841, 3, 939, 52, 693, 5966, 2, 133, 15, 7422, 3512, 1574, 52, 226, 4829, 6, 3847, 15, 63761, 2475, 14, 30, 1708, 1249, 5, 646, 8, 1, 90, 121, 8, 687, 2, 6318, 586, 1, 1507, 1257, 4, 514, 4803, 4876, 72, 15, 1030, 5, 2328, 14740, 34, 64, 11, 77, 629, 9, 6318, 1274, 67, 13, 1, 687, 742, 875, 201, 3, 435, 9, 2097, 500, 1, 1823, 2705, 2072, 1, 737, 1684, 9, 181, 2221, 58, 7718, 1, 284, 51, 12283, 105, 58, 286, 49, 314, 52, 1, 2961, 5, 1, 2072, 2, 34, 47, 1781, 13114, 54, 2144, 19, 1, 1571, 201, 435, 14, 973, 9, 692, 1823, 2705, 232, 58, 57, 2293, 10, 90, 5, 113, 1337, 131, 1477, 248, 6320, 34, 58, 569, 312, 4, 980, 1, 1889, 2, 55, 365, 8, 35, 2286, 8, 55, 1, 263, 374, 853, 3, 12, 226, 380, 18, 6724, 64, 11, 73, 77, 8769, 9, 6318, 2, 4536, 42, 26489, 2, 4003, 52, 14611, 3, 12, 2422, 3, 55, 18, 51, 40615, 105, 8, 609, 3, 371, 10613, 3, 12, 850, 7337], [1, 215, 8012, 2550, 48, 127399, 1147, 10, 7, 47307, 238, 29885, 13, 301, 2, 3753, 217, 37368, 6, 21636, 32618, 3733, 10841, 4, 7, 4830, 2, 51, 445, 105, 1379, 7, 1946, 432, 1434, 301, 1705, 9, 1, 8012, 58, 1115, 10841, 2, 50, 30, 599, 975, 225, 2169, 8, 303, 5, 1, 93, 327, 5167, 25, 58, 235, 57, 762, 4, 26, 35, 1652, 10, 1, 8012, 2, 50, 562, 72, 4, 1, 12369, 8, 1, 814, 4, 946, 98, 24005, 961, 38870, 6, 58, 3667, 127400, 10, 7, 20659, 32618, 121, 36, 1054, 1, 837, 885, 16, 318, 19777, 225, 2169, 38, 13941, 37, 8, 1, 164, 1954, 7, 137, 668, 11, 369, 296, 320, 1423, 2139, 47308, 1072, 4, 788, 3, 14, 3, 12, 35, 1055, 4, 80, 461, 9, 505, 114, 229, 2, 3, 584, 24005, 1476, 5958, 22, 3, 69, 120, 4124, 2, 2077, 120, 4124, 3733, 3220, 505, 14, 7, 393, 2250, 349, 4, 789, 352, 3, 5958, 58, 2158, 67, 7, 7423, 16, 10841, 81, 1, 93, 97, 5167, 2, 6, 1, 8012, 3, 4663, 2540, 22, 25, 127, 923, 25, 87, 4, 120, 184, 11429, 8, 1, 29886, 25, 22, 25, 2642, 4, 10841, 52, 414, 257, 97, 626, 136, 1, 23137, 6, 9, 1, 12284, 2, 1400, 47308, 7445, 8, 4202, 16, 1, 21636, 2, 144, 5958, 24, 1, 1239, 9, 25, 801, 4, 811, 16, 215, 2352, 24, 1, 514, 10841, 135, 766, 4, 1, 8012, 3, 6896, 208, 25, 58, 1519, 49, 36030, 2, 4067, 49, 18788, 6, 5589, 49, 5516, 63, 106, 215, 2540, 93, 885, 208, 5958, 7002, 10909, 20, 1, 1055, 5, 7, 2465, 1942, 4, 1, 29886, 3, 3392, 3, 12, 56, 5, 112, 1812, 123, 45, 27, 4, 91, 376, 367, 165, 1253, 93, 76, 2, 41, 430, 3, 59, 91, 112, 367, 2, 3, 5958, 22, 3, 41, 58, 78, 113, 5, 112, 1695, 578, 9, 2869, 3, 59, 64, 2619, 22, 708, 41, 27, 4, 951, 9, 45, 62, 3, 59, 128, 188, 4111, 2190, 41, 3, 377, 391, 4, 26, 467, 4, 6229, 229, 15, 7, 461, 2, 32, 78, 129, 427, 303, 79, 72, 2, 34, 4, 156, 2, 3, 5711, 2, 45, 3, 377, 391, 4, 120, 9, 349, 8687, 352, 12842, 3, 9, 3, 12, 7, 393, 2250, 4, 91, 16, 2465, 31603, 3, 1722, 10841, 1365, 40, 2208, 2, 4042, 127401, 2, 1908, 7, 1106, 1225, 788, 247, 10841, 3, 12, 768, 11, 4943, 2, 14, 452, 3, 59, 262, 18545, 208, 40, 51, 219, 105, 423, 735, 3297, 1972, 29887, 80981, 10, 1, 627, 3297, 8, 8012, 426, 14, 73, 564, 9, 278, 10841, 2941, 8, 1, 44708, 42, 20, 98, 1046, 2, 56, 5, 215, 3, 12, 175, 79, 27072, 1613, 38, 24921, 3676, 42551, 2, 98, 24005, 4652, 1095, 42, 98, 24005, 40616, 594, 37, 46, 458, 1, 885, 13, 1, 6626, 1, 137, 299, 30, 1, 102, 1426, 985, 13, 1095, 2, 50, 11, 288, 8, 127402, 2, 7085, 2, 543, 4, 4010, 40, 165, 12121, 70, 7, 8688, 80982, 37369, 1054, 40, 885, 93, 115, 1095, 22, 25, 1066, 1, 137, 110, 1393, 225, 24, 7, 21011, 10540, 1594, 16, 44, 3275, 2367, 2989, 80983, 3, 14, 3, 12, 359, 2, 3, 1095, 22, 3, 25, 3, 12, 7, 359, 2540, 25, 62, 1356, 7, 393, 4, 7, 127403, 3, 1095, 3, 12, 636, 30, 262, 67, 12945, 8, 305, 4877, 1177, 1, 23137, 2, 102, 460, 16, 1, 4231, 15540, 2, 34, 25, 22, 25, 2121, 3, 59, 1066, 24, 2208, 6836, 3334, 9, 25, 258, 26, 1298, 215, 3, 39, 3, 429, 89, 49, 2401, 52, 1553, 2, 3, 1095, 22, 3, 14, 3, 12, 57, 7, 1112, 90, 121, 39, 3, 377, 57, 467, 4, 120, 13, 1, 1157, 3836, 39, 3, 702, 89, 120, 83, 63762, 6, 447, 367, 13518, 3, 1, 8012, 2, 50, 1227, 38870, 20, 295, 51, 7486, 105, 8, 918, 2, 58, 9527, 10, 129, 5, 1, 23137, 9, 10841, 18, 72, 5, 48, 380, 914, 1, 10614, 6, 10492, 2, 281, 79, 2170, 2, 54, 73, 1610, 4, 26, 8, 5324, 5, 1, 47309, 2, 16, 83, 20356, 40, 11766, 796, 1, 8012, 3, 780, 15, 7, 946, 25, 18, 581, 10, 7, 229, 276, 2336, 34, 68, 7003, 27073, 391, 7, 8849, 276, 24, 1, 10492, 13, 301, 2, 14, 173, 5639, 56, 5, 10841, 3, 12, 591, 19296, 6, 6145, 1, 362, 2208, 159, 11, 143, 9411, 97, 269, 126, 25916, 6, 42552, 458, 441, 4, 1993, 1428, 10841, 151, 51, 895, 105, 93, 885, 2, 34, 18, 32, 1227, 10001, 19, 1, 37368, 2, 1994, 25, 46, 32, 463, 215, 106, 3286, 2461, 25, 847, 3, 59, 248, 40, 29888, 2, 173, 20, 1, 6534, 6, 8, 1, 1157, 17, 10841, 11, 7, 1390, 7066, 2, 30, 277, 599, 867, 96585, 8, 7, 521, 885, 6, 30, 2158, 72, 80984, 201, 8, 1, 93, 389, 90, 25, 73, 391, 88, 7, 2744, 12525, 16, 1910, 47310, 2714, 8460, 80985, 93, 885, 70, 80985, 3161, 10841, 3, 12, 5204, 10, 1, 686, 13, 40, 1440, 283, 34, 42551, 2, 50, 18, 10841, 3, 12, 14053, 10, 327, 90, 8, 7641, 2, 22, 10841, 3, 12, 2661, 30, 277, 57, 35, 431, 3, 2287, 1, 1769, 532, 3, 59, 179, 132, 2, 3, 42551, 22, 3, 45, 3087, 7, 393, 8, 1, 686, 66, 45, 190, 3, 59, 338, 2, 39, 1763, 45, 3, 674, 26, 496, 361, 123, 45, 3087, 15, 129, 15, 45, 91, 8, 80986, 3, 1, 2847, 5, 40, 238, 6, 40, 1141, 4, 3039, 5516, 38, 40, 1391, 58236, 1435, 11, 127404, 37, 2, 247, 2, 151, 132, 1, 341, 1652, 4, 1461, 1, 8012, 3, 6896, 126, 1993, 1428, 3, 79, 461, 1635, 65, 25, 62, 91, 9, 2590, 211, 72, 2, 3, 5958, 22, 3, 65, 2590, 103, 49, 11, 25, 62, 2414, 7, 393, 66, 2170, 5596, 196, 211, 2, 36, 27, 4, 5596, 4, 132, 2000, 45, 3, 377, 391, 97, 69, 13, 6, 349, 5376, 352, 44709, 42, 770, 95, 9, 67, 14, 505, 1, 647, 5, 80, 6896, 27, 49, 5, 7, 47311, 3, 2218, 3, 526, 1, 215, 201, 2, 2810, 1220, 172, 10, 11104, 3520, 21, 28, 29, 17], [38, 13304, 3252, 6, 584, 7424, 4, 7835, 4133, 5, 53913, 343, 380, 453, 37, 1829, 1064, 38, 37, 208, 893, 160, 224, 191, 50266, 6, 1056, 70941, 53913, 22, 13, 285, 36, 23, 8, 1196, 13, 7, 568, 343, 6, 644, 3721, 5, 1, 97, 220, 1, 97, 4972, 4588, 523, 22, 36, 54, 8, 3985, 1196, 52, 1142, 5, 1, 2847, 6, 64, 18, 77, 7642, 9, 106, 853, 780, 53, 26, 151, 53913, 3, 12, 270, 507, 81, 576, 82, 2, 110, 50266, 3, 12, 226, 1708, 1207, 4431, 50266, 46, 27, 371, 38871, 326, 96, 13, 2225, 895, 4, 128, 35, 780, 42, 2414, 405, 10, 20, 295, 577, 292, 2, 8, 3403, 4, 2823, 4476, 2087, 819, 8, 837, 2, 722, 466, 4, 11628, 1, 97, 220, 4, 846, 7, 33647, 224, 191, 963, 444, 125, 2962, 38, 51, 53914, 125, 37, 127, 32, 210, 859, 51, 268, 5486, 127405, 2962, 441, 19, 5157, 892, 42553, 8, 4688, 17, 740, 19, 3069, 1742, 6, 6258, 29143, 80, 477, 33, 1, 620, 468, 602, 38, 37, 208, 18331, 750, 1005, 38, 38872, 37, 22, 13, 294, 14, 2226, 9, 7, 217, 1474, 115, 27, 2673, 4, 7808, 83, 314, 13, 363, 2674, 105, 2007, 6, 343, 14, 16, 7, 954, 5924, 1, 101, 22, 14, 1600, 1, 314, 947, 1864, 6, 945, 8881, 2, 34, 32, 3214, 15831, 314, 2, 133, 15, 275, 202, 858, 2, 945, 858, 2, 18148, 2, 2723, 18546, 2, 11972, 42, 1679, 3, 12, 2356, 858, 1, 3798, 2, 37370, 1842, 284, 3, 12, 270, 501, 3986, 82, 4, 51, 63763, 383, 517, 605, 2194, 6535, 1000, 1, 1295, 4, 1172, 13, 7, 25917, 427, 16, 682, 13, 294, 25, 22, 1, 1281, 4, 7808, 3318, 314, 18, 151, 577, 4, 1042, 626, 356, 3, 41, 573, 80, 198, 1956, 632, 6, 149, 9, 487, 2, 2288, 730, 4, 820, 626, 356, 2, 41, 2226, 9, 1, 217, 1474, 2673, 4, 7808, 3318, 314, 2, 3, 6535, 22, 77, 836, 7643, 1475, 30, 57, 1698, 2, 6535, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain_seq[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rvn7NZ_iWvDy"
   },
   "outputs": [],
   "source": [
    "word2index = toki.word_index\n",
    "word2index['PAD'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mb3fIeqnWvD2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD\n"
     ]
    }
   ],
   "source": [
    "index2word = toki.index_word\n",
    "index2word[0] = 'PAD'\n",
    "print(index2word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQfOn7v3WvD5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3209 606.142367111134\n"
     ]
    }
   ],
   "source": [
    "#get max length of words\n",
    "\n",
    "lens = [len(text) for text in Xtrain]\n",
    "\n",
    "max_len = max(lens)\n",
    "mean_len = np.mean(lens)\n",
    "\n",
    "print(max_len, mean_len)\n",
    "\n",
    "max_len = int(mean_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLSlD2KSWvD9"
   },
   "outputs": [],
   "source": [
    "#pre-pad the tweets with value 0\n",
    "# that is prepadding (Louis so you understand as well)\n",
    "Xtrain_pad = pad_sequences(Xtrain_seq, maxlen = max_len)\n",
    "Xtest_pad = pad_sequences(Xtest_seq, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0EbZrlOWvEA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130349     True\n",
       "31451     False\n",
       "43541     False\n",
       "Name: hyperp, dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_bin[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_bin = np.asarray([0. if l == False else 1. for l in Ytrain_bin])\n",
    "Ytest_bin = np.asarray([0. if l == False else 1. for l in Ytest_bin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ytrain_bin = to_categorical(Ytrain_bin)\n",
    "# Ytest_bin = to_categorical(Ytest_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest_bin[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_labels = set(Ytrain_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwsprURhWvEE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'left-center': 0, 'right': 1, 'least': 2, 'right-center': 3, 'left': 4})\n"
     ]
    }
   ],
   "source": [
    "label_dict = defaultdict()\n",
    "for i, l in enumerate(mult_labels):\n",
    "    label_dict[l] = i\n",
    "    \n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYe73g-nWvEH"
   },
   "outputs": [],
   "source": [
    "Ytrain_mult = [label_dict[label] for label in Ytrain_mult]\n",
    "Ytest_mult = [label_dict[label] for label in Ytest_mult] \n",
    "\n",
    "# this is now a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCX_ktnIWvEL"
   },
   "outputs": [],
   "source": [
    "no_cls = len(label_dict)\n",
    "\n",
    "Ytrain_mult_cat = np.asarray([to_categorical(label, num_classes = no_cls) for label in Ytrain_mult])\n",
    "Ytest_mult_cat = np.asarray([to_categorical(label, num_classes = no_cls) for label in Ytest_mult])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFn4e9NsWvES"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (38773, 606)\n",
      "Shape of binary label tensor: (38773,)\n",
      "Shape of multilabel tensor: (38773, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', Xtrain_pad.shape)\n",
    "print('Shape of binary label tensor:', Ytrain_bin.shape)\n",
    "print('Shape of multilabel tensor:', Ytrain_mult_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ny9O1CCWvEV"
   },
   "source": [
    "### Prepare the Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aMXU3exWvEW"
   },
   "outputs": [],
   "source": [
    "w2v_path = 'data/GoogleNews-vectors-negative300.bin'\n",
    "embeddings = Word2Vec.load('model_all.bin')\n",
    "embed_len = 100\n",
    "\n",
    "\n",
    "#embed_w2v = KeyedVectors.load_word2vec_format(w2v_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FV5k0356WvEZ"
   },
   "outputs": [],
   "source": [
    "#w = filter(lambda x: x in model.vocab, list(model.wv.vocab))\n",
    "#print model.most_similar(positive=w)\n",
    "\n",
    "def load_embeddings(model, i2w, embed_len):\n",
    "    \n",
    "    index2embed = dict()\n",
    "    w = filter(lambda x: x in word2index.keys(), list(embeddings.wv.vocab))\n",
    "\n",
    "    for i, w in i2w.items():\n",
    "        try:\n",
    "            embed = model[w]\n",
    "        except KeyError:\n",
    "            embed = np.zeros(embed_len)\n",
    "            #embed = embeddings.most_similar(positive=w)\n",
    "        index2embed[i] = embed\n",
    "    \n",
    "    return index2embed\n",
    "\n",
    "def load_w2v(model,i2w):\n",
    "    index2emb = dict()\n",
    "    \n",
    "    for i, w in i2w.items():\n",
    "        try:\n",
    "            embed = model[w]\n",
    "        except KeyError:\n",
    "            embed = model['UNK']\n",
    "            #embed = embeddings.most_similar(positive=w)\n",
    "        index2embed[i] = embed\n",
    "    \n",
    "    return index2embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#index2embed = loadw2v(embed_w2v, index2word)\n",
    "index2embed = load_embeddings(embeddings, index2word, embed_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRT4gSxcWvEc"
   },
   "outputs": [],
   "source": [
    "#compute embedding matrix\n",
    "\n",
    "embedding_matrix = np.zeros((len(word2index) + 1, embed_len))\n",
    "for word, i in word2index.items():\n",
    "    embedding_vector = index2embed[i]\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46WMiWTgWvEf"
   },
   "outputs": [],
   "source": [
    "#load embedding matrix into embedding layer\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(len(word2index) + 1,\n",
    "                            embed_len,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r7rdB0cnWvEi"
   },
   "source": [
    "### Building the classifier - FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrC_iXLNWvEk"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch = 1024\n",
    "#embed_len = 100\n",
    "activation = 'relu'\n",
    "activation_output = 'softmax'\n",
    "loss_function = 'categorical_crossentropy'\n",
    "loss_bin = 'binary_crossentropy'\n",
    "\n",
    "from keras.layers import Conv1D, GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 250\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2aZ89JiBWvEo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 606)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 606, 100)          24449300  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 606, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 604, 250)          75250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 24,587,551\n",
      "Trainable params: 138,251\n",
      "Non-trainable params: 24,449,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "drop1 = Dropout(0.2)(embedded_sequences)\n",
    "\n",
    "conv1 = Conv1D(filters,\n",
    "              kernel_size,\n",
    "              padding = 'valid',\n",
    "              activation = 'relu',\n",
    "              strides = 1)(drop1)\n",
    "\n",
    "pool = GlobalMaxPool1D()(conv1)\n",
    "\n",
    "dense1 = Dense(250, activation='relu')(pool)\n",
    "drop2 = Dropout(0.2)(dense1)\n",
    "\n",
    "output = Dense(1, activation = 'sigmoid')(drop2)\n",
    "\n",
    "\n",
    "#flat = Flatten()(embedded_sequences)\n",
    "#output_1 = Dense(200, activation='relu')(flat)\n",
    "#drop = Dropout(0.4)(output_1)\n",
    "#output_2 = Dense(64, activation='relu')(output_1)\n",
    "#predictions = Dense(2, activation=activation_output)(output_2)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "optimizer = Adam(lr = lr)\n",
    "\n",
    "model.compile(loss=loss_bin, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50Z2bbm4WvEs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "38773/38773 [==============================] - 87s 2ms/step - loss: 0.8109 - accuracy: 0.6441\n",
      "Epoch 2/20\n",
      "38773/38773 [==============================] - 86s 2ms/step - loss: 0.4290 - accuracy: 0.7852\n",
      "Epoch 3/20\n",
      "38773/38773 [==============================] - 85s 2ms/step - loss: 0.3732 - accuracy: 0.8249\n",
      "Epoch 4/20\n",
      "38773/38773 [==============================] - 84s 2ms/step - loss: 0.3448 - accuracy: 0.8409\n",
      "Epoch 5/20\n",
      "38773/38773 [==============================] - 84s 2ms/step - loss: 0.3252 - accuracy: 0.8515\n",
      "Epoch 6/20\n",
      "38773/38773 [==============================] - 85s 2ms/step - loss: 0.3079 - accuracy: 0.8616\n",
      "Epoch 7/20\n",
      "38773/38773 [==============================] - 86s 2ms/step - loss: 0.2906 - accuracy: 0.8718\n",
      "Epoch 8/20\n",
      "38773/38773 [==============================] - 94s 2ms/step - loss: 0.2767 - accuracy: 0.8783\n",
      "Epoch 9/20\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(Xtrain_pad, Ytrain_bin, batch_size=batch, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hm13g7AWvEv"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(Xtest_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00331014],\n",
       "       [0.03838509],\n",
       "       [0.06277174],\n",
       "       [0.9436791 ],\n",
       "       [0.6695579 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_converted = [0 if p < 0.5 else 1 for p in predictions]\n",
    "pred_converted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrojzAtiWvEx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88      4813\n",
      "         1.0       0.87      0.91      0.89      4881\n",
      "\n",
      "    accuracy                           0.89      9694\n",
      "   macro avg       0.89      0.89      0.89      9694\n",
      "weighted avg       0.89      0.89      0.89      9694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(predictions, axis=1)\n",
    "#Ytest_converted = np.argmax(Ytest_bin, axis=1)\n",
    "\n",
    "print(classification_report(Ytest_bin, pred_converted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "embed_lstm.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
